{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soham2710/Plant-Disease-Detection/blob/main/Plant_Diseases_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWE_V85SiPs0"
      },
      "source": [
        "In this project we will create a Convolutional Neural Network which will be able to predict whether a plant is suffering from a disease. We will use different layers and other hyperparameters for building, training and testing this classifictaion model.We will be using tensorflow and keras for this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTIsIhasrmHY",
        "outputId": "33578b13-cee2-4ba8-d00e-59560ade7eb9"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRNql8QqjfMR"
      },
      "source": [
        "First we will mount our google drive on colab so that we can use the dataset directly from our drive. For this you first need to upload the data on your drive and then mount the drive on colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F9HPaEprtqo",
        "outputId": "6d37b8f1-8b39-4ce6-9d0f-9a66e881c410"
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/MyDrive\".\n",
        "!ls \"/content/drive/MyDrive\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 01-Powerpoint-Infographics.zip\n",
            "'0401 Himanshu.pdf'\n",
            "'0402 Himanshu.pdf'\n",
            "'0403 Himanshu.pdf'\n",
            "'0404 Meet Garg.pdf'\n",
            "'0405 Harish Kumar Mishra.pdf'\n",
            "'0406 Himanshu.pdf'\n",
            "'0407 Mohit Sehgal.pdf'\n",
            "'0408 Seema Mandal.pdf'\n",
            "'0409 Utsav Bharadwaj.pdf'\n",
            "'0410 Bhawna.pdf'\n",
            "'0411 Col. Sehgal.pdf'\n",
            "'0412 Mahesh Varshney.pdf'\n",
            "'0413 Debatiya.pdf'\n",
            "'0414 Ishwar Chandra Sharma.pdf'\n",
            "'0415 Sudhir Kumar.pdf'\n",
            "'0416 Sharmilee Rabha.pdf'\n",
            "'0417 Abhisheck.pdf'\n",
            "'0418 Sonali Dixit.pdf'\n",
            "\"0419 Savio D'Cunha.pdf\"\n",
            "'0420 Ajay Yadav.pdf'\n",
            "'0421 Govind Bhai.pdf'\n",
            "'10k backlink list-SEO.xlsx'\n",
            "'10kstartups India MOU.gdoc'\n",
            " 1111.zip\n",
            "'111 (2).jpg'\n",
            " 1599995228696.png\n",
            " 1.png\n",
            " 20140220_143308.jpg\n",
            "'2023 Content Calendar Template.gsheet'\n",
            " 2.png\n",
            " 3.png\n",
            "'89117130603 - Registration Report (2).csv'\n",
            "'89117130603 - Registration Report (2).gsheet'\n",
            "'90 Degrees Corporate Profile Final.pdf'\n",
            "'Account statement Canara Bank.pdf'\n",
            "'Advanced Google Analytics.pdf'\n",
            "'Agile approach to data strategy content ideas.gsheet'\n",
            "'AI Challenges.docx'\n",
            " Airtable.gdoc\n",
            " Aladlegal.gdoc\n",
            "'Alpha One'\n",
            " AMA.gdoc\n",
            "'analytics 2.png'\n",
            " analytics.png\n",
            " Annexure-Soham.pdf\n",
            " application.pdf\n",
            " Articles\n",
            " AspiringPM.gsheet\n",
            " Attendee_Summary_Report_1487761163603_20230413_1135.xlsx\n",
            " audio1526183293.m4a\n",
            " audio_only.m4a\n",
            "'Awesome Computer Vision.gdoc'\n",
            "'back visiting card.jpg'\n",
            "'back visiting card.psd'\n",
            " bl1CATmenwomenshoppingcol.jpg\n",
            "'Blog Post Product Newsletter 2 .gdoc'\n",
            " Book1-Babu.xlsx\n",
            " Botmartz\n",
            "'BotMartz Business.gsheet'\n",
            " Brief-on-State-of-Human-Trafficking_Roundtable-1.pdf\n",
            " calendar-oct-18.jpg\n",
            "'Candidate List for Anthony.gsheet'\n",
            "'Cap America Freight Estimator.gsheet'\n",
            " Certificates.gsheet\n",
            " chat.txt\n",
            "'Chrome Passwords.csv'\n",
            "'Client list.gsheet'\n",
            "'Colab Notebooks'\n",
            "'Collect Chat.gdoc'\n",
            "'College Reachouts.gdoc'\n",
            " Community.gif\n",
            "'COMPANY INTRO.pdf'\n",
            "'compare - Links (1).csv'\n",
            "'Comparing AutoML Frameworks: A Comprehensive Review.gdoc'\n",
            "'Contact Information (1).gform'\n",
            "'Contact Information.gform'\n",
            "'Content for Backlinks.gdoc'\n",
            "'Copy of ChatGPT for Product Managers.gdoc'\n",
            "'Copy of Data Scientists Emails.gsheet'\n",
            "'Copy of Projects List November Update.pdf'\n",
            "'Copy of Top 3 Skills Every Successful Product Manager Should Have.docx'\n",
            "'Core Web Vitals.gsheet'\n",
            " Costing.txt\n",
            "'Course for Upskill.gdoc'\n",
            " cs.jpg\n",
            " CTOs.gsheet\n",
            " Customer-Churn-Records.csv\n",
            "'Daily updates.gsheet'\n",
            " Data\n",
            "'Data base.gsheet'\n",
            "'Data Science learning.gdoc'\n",
            "'Data Scientist.gsheet'\n",
            "'Data Scientists Emails.gsheet'\n",
            "'Day 1 - 3 minute challenge RentSpace.xlsx'\n",
            "'Day 1 - Superstore.xls'\n",
            "'Day 2 - Competitor Blend.xlsx'\n",
            "'Day 2 - Joins Basics.xlsx'\n",
            "'Day 3 - Customer Database.xlsx'\n",
            "'Day 3 - India Life expectancy.pdf'\n",
            "'Day 4 - Africa Exports.xlsx'\n",
            "'Day 4 - Outlet & Salesman Cost Date.xlsx'\n",
            "'Day 4 - US City & State Details CSV file.csv'\n",
            "'Day 5 - EU Bank Customers.csv'\n",
            "'Day 5 - Euro Image.png'\n",
            "'Digital Transformation as a global issue.pdf'\n",
            " Divi\n",
            " Documents\n",
            " Downloads\n",
            "'DS AI ML Newsletter.gform'\n",
            "'DSS Seattle Event.gsheet'\n",
            " EAadhaar_853010517987_02102020154127_738769.pdf\n",
            "'Ekobae all Passwords.gdoc'\n",
            "'Email report.gsheet'\n",
            "'Ensemble Learning Coding.gdoc'\n",
            "'Entrepreneur Registration (File responses)'\n",
            "'Entrepreneur Registration.gform'\n",
            "'Ethical Data Science.gdoc'\n",
            " Event.gsheet\n",
            "'Excel questions.gdoc'\n",
            " Expenditure.gsheet\n",
            " Expenses.gsheet\n",
            "'Experienced  PM.gsheet'\n",
            " facebook-sohamsharma104.zip\n",
            " Facing_Your_Fears_As_An_Entrepreneur.gdoc\n",
            "'Featuring 50 Founders.gform'\n",
            "'Flavortrail Marketing Plan.gdoc'\n",
            "'Flavortrail Tos.gdoc'\n",
            "'GDG events planning.gdoc'\n",
            " gender-equilty-5pcaiga.jpg\n",
            "'gender inequality.jpg'\n",
            "'girl cage1.jpg'\n",
            "'girl cage.jpg'\n",
            "'Gradient Boosting Machines.gdoc'\n",
            "'Guided Projects.gif'\n",
            "'HIGH DA PA WEBSITES WITH INSTANT COMMENT BACKLINK APPROVAL & Guest Posts Fast Indexer.gsheet'\n",
            "'Hirect invoice_Soham Sharma.pdf'\n",
            "'How AI can transform Emergency Radiology.gdoc'\n",
            "'How Prowess Works.png'\n",
            "'https:  www.showprowess.com -Coverage-2022-12-20.gsheet'\n",
            "'https:  www.showprowess.com -Coverage-2023-06-20.gsheet'\n",
            "'https:  www.showprowess.com -Coverage-Valid-2023-03-02.gsheet'\n",
            "'Human rights day.jpg'\n",
            "'Ian Koniak.gsheet'\n",
            "'IBIS Conferences Prospecting.gsheet'\n",
            "'i card.pptx'\n",
            "'i cards nisworg.jpg'\n",
            "'I cards print.docx'\n",
            "'i cards_updated.png'\n",
            "\"I didn't kill my father.gdoc\"\n",
            " IMG-20150802-WA0016.jpg\n",
            " IMG_20150804_191937.jpg\n",
            " IMG_20150804_192052.jpg\n",
            " IMG_20150804_192106.jpg\n",
            " IMG_20150804_192149.jpg\n",
            " IMG_20150804_192215.jpg\n",
            " IMG_20150804_192229.jpg\n",
            " IMG_20150804_192238.jpg\n",
            " IMG_20150804_192330.jpg\n",
            " IMG_20150804_192438.jpg\n",
            " IMG_20150804_192501.jpg\n",
            " IMG_20150804_192548.jpg\n",
            "'IMG_20150804_192620 (1).jpg'\n",
            " IMG_20150804_192620.jpg\n",
            " IMG-20150805-WA0011.jpg\n",
            " IMG-20150805-WA0012.jpg\n",
            " IMG-20150805-WA0013.jpg\n",
            " IMG_20151028_193946_15CS.jpg\n",
            " IMG_20151028_194005_1CS.jpg\n",
            " IMG-20151214-WA0024.jpg\n",
            " IMG_20160331_141805.jpg\n",
            " IMG-20170224-WA0002.jpg\n",
            " IMG_20180301_191800.jpg\n",
            " IMG.jpg\n",
            " InfoGrapia\n",
            "'information brochure.pdf'\n",
            " Internship\n",
            "'Internship form (File responses)'\n",
            "'Internship form.gform'\n",
            " Intro.png\n",
            " Invoice.gsheet\n",
            "'Job Description.gdoc'\n",
            "'Job Recruitment app.gdoc'\n",
            " JOBS_Prowess.gsheet\n",
            "'jobs prowess posted.gsheet'\n",
            "'Kota Doriya Saree.gdoc'\n",
            "'Layered Map.gmap'\n",
            "'Leads - Social media.gsheet'\n",
            "'Learning Resources.gsheet'\n",
            "'LICENSE FRONT.jpg'\n",
            "'LinkedIn URL.gsheet'\n",
            "'Mad Content Calendar.gsheet'\n",
            " Marketing\n",
            " Marksheet.jpg\n",
            "'Marriage expenses.gsheet'\n",
            " Matplotlib_ass.ipynb\n",
            "'May 2021.gsheet'\n",
            "'mech_10.material science.pdf'\n",
            "'ML Basics.gsheet'\n",
            " my_pari.mp4\n",
            "'Navigating Product Failures: A Roadmap to Learning and Pivoting for Success.gdoc'\n",
            "'Navratri List.gsheet'\n",
            "'New Doc 2.pdf'\n",
            "'New Product Launch: Description & The Process.gdoc'\n",
            "'Newsletter document.gdoc'\n",
            " Nisworg\n",
            " NMM.gsheet\n",
            " NOC.jpg\n",
            " Pages.gsheet\n",
            "'PAID SITES LIST (1).gsheet'\n",
            "'PAID SITES LIST.gsheet'\n",
            "'Petar Mitrov  chat.gdoc'\n",
            "'photo6206344398782966670 (1).jpg'\n",
            "'Pitch deck.gdoc'\n",
            " Podcast.gdoc\n",
            " Powerweave\n",
            "'Predicting Customer Churn in Banking: A Machine Learning Approach.gdoc'\n",
            "\"Prioritized Growth Plan - Soham's Edition.gdoc\"\n",
            " ProductCollective+ProductFolks.gsheet\n",
            "'Product Management vs Project Management.gdoc'\n",
            "'Product manager Course'\n",
            "'Project proposal.gdoc'\n",
            "'Project requirement Document (VaultHR).gdoc'\n",
            " Projects.gif\n",
            " Proposal.docx\n",
            "'Prowess Community Project.gsheet'\n",
            "'Prowess Content Calender.gsheet'\n",
            "'Prowess Home + blog page changes.gdoc'\n",
            "'Prowess marketing.gdoc'\n",
            "'Prowess SEO.gdoc'\n",
            "'Prowess templates.gdoc'\n",
            "'Pseudo Codes for Training GBM.gdoc'\n",
            " recording.conf\n",
            " resources.gif\n",
            "'Review Personalized Skills Map.png'\n",
            "'Role of User Experience in Product Management.gdoc'\n",
            "'Roles of AI.gdoc'\n",
            "'Sales Course Reachout.gsheet'\n",
            " Seaborn_ass.ipynb\n",
            "'SEO Contract Work'\n",
            "'SEO Data and backlinks sites.gsheet'\n",
            "'SEO Metrics.gsheet'\n",
            "'SEO Work–.gdoc'\n",
            "'ShowProwess Email Marketing.gdoc'\n",
            " signature1.jpg\n",
            "'Skills Keyword Mapping.gdoc'\n",
            "'Smart College Idea.gdoc'\n",
            "'Social media posts.gdoc'\n",
            "'Soham 2_extraction_2023-12-03T12_01_24.438Z.csv'\n",
            "'Soham 3_extraction_2023-12-03T12_00_54.913Z.csv'\n",
            "'soham 4_extraction_2023-12-03T12_00_20.281Z.csv'\n",
            "'Soham 5_extraction_2023-12-03T11_59_44.980Z.csv'\n",
            " Soham_Sharma_15thMay\n",
            " SohamSharma_15thMay_homeassignment3.ipynb\n",
            "'Soham'\\''s Story (Autosaved) (1).docx'\n",
            "'Soham'\\''s Story (Autosaved).docx'\n",
            "'Sponsor List.gsheet'\n",
            "'State Common Entrance Test Cell, Maharashtra State, Mumbai.pdf'\n",
            "'Sugar Level Updates.gsheet'\n",
            "'Sustainable Infrastructure Practices for Ethical AI Development.gdoc'\n",
            "'syt-zjkq-hsj - Oct 5, 2023.gjam'\n",
            "'Task Division.gsheet'\n",
            " Tax-interview.pdf\n",
            " The_First_Six_Books_of_the_Elements_of_Euclid_by_John_Casey_and_Euclid.pdf\n",
            "'The Full List of 1000 Slack Communities.gsheet'\n",
            "'The School App.gdoc'\n",
            "'Third set.gjam'\n",
            "'ThriveCast Brian Paget01 - Made with Clipchamp_1696845724040.mp4'\n",
            "'Titanic (kaggle).gdoc'\n",
            "'Top 8 Types of Product Managers.gdoc'\n",
            "'Topics for Ofentse.gdoc'\n",
            "'Ui changes.gdoc'\n",
            "'Understanding AI: A Comprehensive Journey.gdoc'\n",
            "'Understanding Plots Charts and its use case scenario.gdoc'\n",
            "'Unfollow list.gsheet'\n",
            "'Unlock Your Product Management Potential: 10 Free Online Product Management Courses to Enhance Your Skills and Drive Success.gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Vault HR content for backlinks.gdoc'\n",
            "'VaultHR SEO sheet.gsheet'\n",
            "'Video-20230908_182851-Meeting Recording.mp4'\n",
            "'VP of Product.gsheet'\n",
            "'Warranty Registration (File responses)'\n",
            "'Warranty Registration.gform'\n",
            "'Web Content Sample.gdoc'\n",
            "'Websites developed previously.docx'\n",
            "'WhatsApp Image 2021-04-23 at 12.32.31 PM.jpeg'\n",
            "'WhatsApp Image 2021-04-23 at 12.32.32 PM (2).jpeg'\n",
            "'WhatsApp Image 2021-05-18 at 7.06.18 PM.jpeg'\n",
            "'WhatsApp Image 2021-05-18.jpeg'\n",
            "'Workday Transcription.gdoc'\n",
            "'Work Portfolio- Social Media Marketing & Google Ads.docx'\n",
            "'Writing A Product Roadmap.gdoc'\n",
            "'Yes Bank Statement.pdf'\n",
            "'ziplyne 1.PNG'\n",
            " ziplyne2.PNG\n",
            " ziplyne3.PNG\n",
            "'Zpound crypto project.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-uW8bmlkNRg"
      },
      "source": [
        "After mounting our drive we will locate the folder where our data is stored to use it in our colab notebook.\n",
        "Here you can see that I have 2 folders in my drive and 'Plant_images_pianlytix'  contains the images that we will work on."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install keras.preprocessing --upgrade"
      ],
      "metadata": {
        "id": "a0TzFnuvMMiv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVSkISgRvTK8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import label_binarize,  LabelBinarizer\n",
        "from keras.preprocessing import image\n",
        "#from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import model_from_json\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BMZmG5jldCj"
      },
      "source": [
        "Next we will import all the required libraries. As we are making a CNN model we will import all the required layers, activations, optimizers, etc.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH1pl8Pmpjbf"
      },
      "source": [
        "# Plotting 12 images to check dataset\n",
        "plt.figure(figsize=(12,12))\n",
        "path = \"/content/drive/MyDrive/Data/Plant_images/Potato___Early_blight\"\n",
        "for i in range(1,17):\n",
        "    plt.subplot(4,4,i)\n",
        "    plt.tight_layout()\n",
        "    rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))\n",
        "    plt.imshow(rand_img)\n",
        "    plt.xlabel(rand_img.shape[1], fontsize = 10)#width of image\n",
        "    plt.ylabel(rand_img.shape[0], fontsize = 10)#height of image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhGPvhb8l7_2"
      },
      "source": [
        "Now we will observe some of the iamges that are their in our dataset. We will plot 12 images here using the matplotlib library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERSCAiVU5Vbd"
      },
      "source": [
        "#Converting Images to array\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, (256,256))\n",
        "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPy1pFxa3ZIR"
      },
      "source": [
        "After visualizing the images let us move forward and create a function which will convert the images into a numpy array. It is required because we will normalize our dataset after this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhte_44Fr43o"
      },
      "source": [
        "dir = \"/content/drive/MyDrive/Data/Plant_images\"\n",
        "root_dir = os.listdir(dir)\n",
        "image_list, label_list = [], []\n",
        "all_labels = ['Corn-Common_rust', 'Potato-Early__blight', 'Tomato-Bacterial_spot']\n",
        "binary_labels = [0,1,2]\n",
        "temp = -1\n",
        "\n",
        "# Reading and converting image to numpy array\n",
        "for subdir in root_dir:\n",
        "  plant_image_list = listdir(f\"{dir}/{subdir}\")\n",
        "  temp += 1\n",
        "  for files in plant_image_list:\n",
        "    image_path = f\"{dir}/{subdir}/{files}\"\n",
        "    image_list.append(convert_image_to_array(image_path))\n",
        "    label_list.append(binary_labels[temp])\n",
        "\n",
        "# Visualize the number of classes count\n",
        "label_counts = pd.DataFrame(label_list).value_counts()\n",
        "label_counts.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjEAueGv4yPX"
      },
      "source": [
        "Now we will convert all the images into numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GnSjx-aqT6I"
      },
      "source": [
        "# Visualize the number of classes count\n",
        "label_counts = pd.DataFrame(label_list).value_counts()\n",
        "label_counts.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfn1LTwP6qmp"
      },
      "source": [
        "We will also observe the number of images under different classes to see if the dataset is balanced or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPqSYwxqd2j"
      },
      "source": [
        "image_list[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuI5Pgoa7lGx"
      },
      "source": [
        "Next we will observe the shape of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84jyMC3g6A2I"
      },
      "source": [
        "label_list = np.array(label_list)\n",
        "label_list.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QmqfbOX7rbi"
      },
      "source": [
        "Checking the total number of the images which is the length of the labels list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uj2tiS99gjD"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_hPmZcH8xsC"
      },
      "source": [
        "Next we will use sklearn train_test_split to split the dataset into testing and training data. Here I have taken test size as 0.2 so my data will be divided into 80% training and 20% testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k79Lrwn9dxs"
      },
      "source": [
        "x_train = np.array(x_train, dtype=np.float16) / 225.0\n",
        "x_test = np.array(x_test, dtype=np.float16) / 225.0\n",
        "x_train = x_train.reshape( -1, 256,256,3)\n",
        "x_test = x_test.reshape( -1, 256,256,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape,y_test.shape,x_train.shape,y_train.shape"
      ],
      "metadata": {
        "id": "3XhfSVDLWH-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxx3natj8jc9"
      },
      "source": [
        "Now we will normalize the dataset of our images. As pixel values ranges from 0 to 255 so we will divide each image pixel with 255 to normalize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGh439ZAqK1p"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggVzpCbb9kp-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(256,256,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE4moAAbo9ET"
      },
      "source": [
        "Next we will create a network architecture for the model. We have used different types of layers according to their features namely Conv_2d (It is used to create a convolutional kernel that is convolved with the input layer to produce the output tensor), max_pooling2d (It is a downsampling technique which takes out the maximum value over the window defined by poolsize), flatten (It flattens the input and creates a 1D output), Dense (Dense layer produce the output as the dot product of input and kernel).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSZceAYY-Yu4"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0001),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwjP40jjpPo0"
      },
      "source": [
        "While compiling the model we need to set the type of loss which will be Binary Crossentropy for our model alongwith this we also need to set the optimizer and the metrics respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTHjVTuA_Zjb"
      },
      "source": [
        "# Splitting the training data set into training and validation data sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFPtXVeoqJgv"
      },
      "source": [
        "Next we will split the dataset into validation and training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9aUasny_DY7"
      },
      "source": [
        "# Training the model\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs,\n",
        "                    validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjVpmPlkqVT6"
      },
      "source": [
        "Fitting the model with the data and finding out the accuracy at each epoch to see how our model is learning. Now we will train our model on 10 epochs and a batch size of 128. You can try using more number of epochs to increase accuracy but here we can see that the model has already raeched a very high accuracy so we don't need to run it for more. During each epochs we can see how the model is performing by viewing the training and validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Bcb5S6irlP"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/Data/Plant_images/plant_disease.h5\")\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "#save the model architecture to JSON file\n",
        "with open('/content/drive/My Drive/Data/Plant_images/plant_model.json', 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "#saving the weights of the model\n",
        "model.save_weights('/content/drive/My Drive/Data/Plant_images/plant_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fuuVxsUJ9Cd"
      },
      "source": [
        "Saving the model using different techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJmXMcse_i8H"
      },
      "source": [
        "#Plot the training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(history.history['accuracy'], color='r')\n",
        "plt.plot(history.history['val_accuracy'], color='b')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'val'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVLGbxJxKCZ2"
      },
      "source": [
        "Next we will plot the accuracy of the model for the trainig history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIOUuhjT_tjf"
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKXkfQ-bKL8e"
      },
      "source": [
        "Evaluating the model to know the accuracy of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIQQPjLFjXQX"
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMMMLTuNKVcU"
      },
      "source": [
        "Next we will use our model to predict predicting the testing dataset label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_hJC19oD7j"
      },
      "source": [
        "# Plotting image to compare\n",
        "img = array_to_img(x_test[50])\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giGnMYE5_t_-"
      },
      "source": [
        "# Finding max value from predition list and comaparing original value vs predicted\n",
        "print(\"Originally : \",all_labels[np.argmax(y_test[10])])\n",
        "print(\"Predicted : \",all_labels[np.argmax(y_pred[10])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkJqzX1wKort"
      },
      "source": [
        "Printing out the original and the predicted label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvSmgEsAK1Zu"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD41lY1sK7-J"
      },
      "source": [
        "We started with loading the dataset into google colab using google drive and visualizing the images. Normalizing is an important step when working with any type of dataset. After that we created a CNN Model which is further used for predicting the plant diseases using the image supplied to model.\n",
        "This model is highly beneficial as it can be used by different agricultural firms and farmers to increase their yield and stop wastage of crops due to disease."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### App Building"
      ],
      "metadata": {
        "id": "H4t5QE3a_KCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "33XOIjdr8NbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "5ls7VWoI8OrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/drive/MyDrive/Data/Plant_images/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "1IiihyHf8ZBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "JOaNP5PF8e4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}